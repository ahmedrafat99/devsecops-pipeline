name: DevSecOps Pipeline
# trigger: manual touch to run workflow

on:
  push:
    branches:
      - main
    paths:
      - "python/**"
      - ".github/workflows/python-devsecops.yml"
  pull_request:
    branches:
      - main
    paths:
      - "python/**"
      - ".github/workflows/python-devsecops.yml"
  workflow_dispatch:

permissions:
  contents: read
  actions: read
  security-events: write

jobs:
  devsecops:
    if: github.actor != 'dependabot[bot]'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout source
        uses: actions/checkout@v4

      - name: Detect project directory
        id: project
        shell: bash
        run: |
          if [ -f "python/manage.py" ]; then
            echo "dir=python" >> "$GITHUB_OUTPUT"
          else
            echo "Could not find python/manage.py"
            exit 1
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Create report directories
        shell: bash
        run: |
          mkdir -p "${{ steps.project.outputs.dir }}/reports"

      - name: Secrets scan - Gitleaks (SARIF)
        shell: bash
        run: |
          docker run --rm -v "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}:/repo" zricethezav/gitleaks:latest detect \
            --source="/repo" \
            --report-format sarif \
            --report-path "/repo/reports/gitleaks.sarif" \
            --exit-code 0
        continue-on-error: true

      - name: Secrets scan - TruffleHog (JSON)
        shell: bash
        run: |
          docker run --rm -v "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}:/repo" trufflesecurity/trufflehog:latest filesystem \
            --directory=/repo \
            --json > "${{ steps.project.outputs.dir }}/reports/trufflehog.json" || true
          if [ ! -s "${{ steps.project.outputs.dir }}/reports/trufflehog.json" ]; then
            echo "[]" > "${{ steps.project.outputs.dir }}/reports/trufflehog.json"
          fi
        continue-on-error: true

      - name: Install application and security tooling
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install "safety<3" semgrep
          pip install --upgrade pip-audit
          python - <<'PY'
          import importlib.util
          import subprocess
          import sys

          # Some runner environments resolve an incompatible cyclonedx library.
          # pip-audit imports `cyclonedx.parser`, so ensure that module exists.
          if importlib.util.find_spec("cyclonedx.parser") is None:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "cyclonedx-python-lib<4"])
          PY

      - name: SCA - Safety
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          safety check -r requirements.txt --full-report --json > reports/safety.json || true
          safety check -r requirements.txt --full-report > reports/safety.txt || true
          if [ ! -s reports/safety.json ]; then
            echo '{"status":"missing","message":"Safety JSON output was not generated; see safety.txt for full details."}' > reports/safety.json
          fi
        continue-on-error: true

      - name: SCA - pip-audit
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          set +e
          python -m pip show pip-audit cyclonedx-python-lib > reports/pip-audit-env.txt 2>&1
          python - <<'PY' >> reports/pip-audit-env.txt 2>&1
          import importlib.util
          print("cyclonedx.parser module found:", bool(importlib.util.find_spec("cyclonedx.parser")))
          PY
          python -m pip_audit -r requirements.txt --format json --output reports/pip-audit.json > reports/pip-audit-json.log 2>&1
          python -m pip_audit -r requirements.txt > reports/pip-audit.txt 2>&1
          # If text output is empty, preserve JSON-run logs for troubleshooting.
          if [ ! -s reports/pip-audit.txt ] && [ -s reports/pip-audit-json.log ]; then
            cp reports/pip-audit-json.log reports/pip-audit.txt
          fi
          if [ ! -s reports/pip-audit.json ]; then
            echo '{"dependencies":[],"vulnerabilities":[],"message":"pip-audit JSON output was not generated; see pip-audit.txt for details."}' > reports/pip-audit.json
          fi
          exit 0
        continue-on-error: true

      - name: SAST - Semgrep (SARIF)
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          semgrep scan --config auto --sarif --output reports/semgrep.sarif .
          semgrep scan --config auto . > reports/semgrep.txt
        continue-on-error: true

      - name: SCA - Trivy filesystem scan (Python dependencies)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: fs
          scan-ref: ${{ steps.project.outputs.dir }}
          vuln-type: library
          severity: CRITICAL,HIGH,MEDIUM
          format: sarif
          output: ${{ steps.project.outputs.dir }}/reports/trivy-deps.sarif
        continue-on-error: true

      - name: Build Docker image
        run: docker build -t pygoat:ci -f ${{ steps.project.outputs.dir }}/Dockerfile ${{ steps.project.outputs.dir }}

      - name: Container scan - Trivy image (human-readable)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: pygoat:ci
          vuln-type: os,library
          severity: CRITICAL,HIGH,MEDIUM
          format: table
          output: ${{ steps.project.outputs.dir }}/reports/trivy-image.txt
        continue-on-error: true

      - name: Container scan - Trivy image (SARIF)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: pygoat:ci
          vuln-type: os,library
          severity: CRITICAL,HIGH,MEDIUM
          format: sarif
          output: ${{ steps.project.outputs.dir }}/reports/trivy-image.sarif
        continue-on-error: true

      - name: Start app container for DAST
        run: |
          docker network create zap-net || true
          docker run -d --name pygoat-app -p 8000:8000 --network zap-net \
            pygoat:ci \
            sh -c "python manage.py migrate --noinput && gunicorn --bind 0.0.0.0:8000 --workers 3 --threads 2 --timeout 60 pygoat.wsgi:application"
          for i in {1..45}; do
            if docker run --rm --network zap-net curlimages/curl:8.10.1 -fsS http://pygoat-app:8000/ > /dev/null; then
              echo "App is reachable for ZAP."
              exit 0
            fi
            sleep 2
          done
          echo "App did not become ready in time. Container logs:"
          docker logs pygoat-app || true
          exit 1

      # OWASP ZAP baseline: DAST scan against a live running app endpoint.
      - name: DAST - OWASP ZAP baseline scan
        id: zap_baseline_step
        run: |
          chmod -R 777 "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}/reports" || true
          docker run --rm --network zap-net \
            --user root \
            -v "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}/reports:/zap/wrk/:rw" \
            ghcr.io/zaproxy/zaproxy:stable zap-baseline.py \
            -t http://pygoat-app:8000 \
            -l INFO \
            -r zap-report.html \
            -J zap-report.json \
            -x zap-report.xml \
            -w zap-warnings.md
        continue-on-error: true

      - name: Preserve ZAP baseline artifacts
        if: always()
        shell: bash
        env:
          REPORT_DIR: ${{ steps.project.outputs.dir }}/reports
        run: |
          [ -f "$REPORT_DIR/zap-report.html" ] && cp "$REPORT_DIR/zap-report.html" "$REPORT_DIR/zap-baseline-report.html" || true
          [ -f "$REPORT_DIR/zap-report.json" ] && cp "$REPORT_DIR/zap-report.json" "$REPORT_DIR/zap-baseline-report.json" || true
          [ -f "$REPORT_DIR/zap-report.xml" ] && cp "$REPORT_DIR/zap-report.xml" "$REPORT_DIR/zap-baseline-report.xml" || true
          [ -f "$REPORT_DIR/zap-warnings.md" ] && cp "$REPORT_DIR/zap-warnings.md" "$REPORT_DIR/zap-baseline-warnings.md" || true

      - name: DAST - OWASP ZAP full (active) scan
        id: zap_full_step
        run: |
          chmod -R 777 "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}/reports" || true
          docker run --rm --network zap-net \
            --user root \
            -v "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}/reports:/zap/wrk/:rw" \
            ghcr.io/zaproxy/zaproxy:stable zap-full-scan.py \
            -t http://pygoat-app:8000 \
            -m 20 \
            -a \
            -l INFO \
            -r zap-report.html \
            -J zap-report.json \
            -x zap-report.xml \
            -w zap-warnings.md \
            -z "-config spider.maxDuration=10 -config scanner.threadPerHost=5 -config connection.timeoutInSecs=60"
        continue-on-error: true

      - name: Normalize ZAP artifacts
        if: always()
        shell: bash
        env:
          REPORT_DIR: ${{ steps.project.outputs.dir }}/reports
        run: |
          if [ ! -f "$REPORT_DIR/zap-report.html" ]; then
            cat > "$REPORT_DIR/zap-report.html" <<'EOF'
          <html><body><h1>ZAP report missing</h1><p>ZAP did not generate this report in this run. Check the DAST step logs.</p></body></html>
          EOF
          fi
          if [ ! -f "$REPORT_DIR/zap-report.json" ]; then
            cat > "$REPORT_DIR/zap-report.json" <<'EOF'
          {"status":"missing","message":"ZAP did not generate JSON report in this run. Check the DAST step logs."}
          EOF
          fi
          if [ ! -f "$REPORT_DIR/zap-report.xml" ]; then
            cat > "$REPORT_DIR/zap-report.xml" <<'EOF'
          <report status="missing" message="ZAP did not generate XML report in this run. Check the DAST step logs."/>
          EOF
          fi
          if [ ! -f "$REPORT_DIR/zap-warnings.md" ]; then
            cat > "$REPORT_DIR/zap-warnings.md" <<'EOF'
          # ZAP warnings
          ZAP warnings report was not generated in this run.
          EOF
          fi

      - name: Stop app container
        if: always()
        run: |
          docker rm -f pygoat-app || true
          docker network rm zap-net || true

      - name: Convert supplemental reports to SARIF
        if: always()
        shell: bash
        run: |
          python scripts/security_json_to_sarif.py \
            --report-dir "${{ steps.project.outputs.dir }}/reports" \
            --tools trufflehog,safety,pip-audit,zap-baseline,zap-full

      - name: Ensure report placeholders before SARIF upload
        if: always()
        shell: bash
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          [ -f reports/semgrep.sarif ] || echo '{"version":"2.1.0","$schema":"https://json.schemastore.org/sarif-2.1.0.json","runs":[]}' > reports/semgrep.sarif
          [ -f reports/trivy-deps.sarif ] || echo '{"version":"2.1.0","$schema":"https://json.schemastore.org/sarif-2.1.0.json","runs":[]}' > reports/trivy-deps.sarif
          [ -f reports/trivy-image.sarif ] || echo '{"version":"2.1.0","$schema":"https://json.schemastore.org/sarif-2.1.0.json","runs":[]}' > reports/trivy-image.sarif
          [ -f reports/gitleaks.sarif ] || echo '{"version":"2.1.0","$schema":"https://json.schemastore.org/sarif-2.1.0.json","runs":[]}' > reports/gitleaks.sarif
          [ -f reports/trufflehog.sarif ] || echo '{"version":"2.1.0","$schema":"https://json.schemastore.org/sarif-2.1.0.json","runs":[]}' > reports/trufflehog.sarif
          [ -f reports/safety.sarif ] || echo '{"version":"2.1.0","$schema":"https://json.schemastore.org/sarif-2.1.0.json","runs":[]}' > reports/safety.sarif
          [ -f reports/pip-audit.sarif ] || echo '{"version":"2.1.0","$schema":"https://json.schemastore.org/sarif-2.1.0.json","runs":[]}' > reports/pip-audit.sarif
          [ -f reports/zap-baseline.sarif ] || echo '{"version":"2.1.0","$schema":"https://json.schemastore.org/sarif-2.1.0.json","runs":[]}' > reports/zap-baseline.sarif
          [ -f reports/zap-full.sarif ] || echo '{"version":"2.1.0","$schema":"https://json.schemastore.org/sarif-2.1.0.json","runs":[]}' > reports/zap-full.sarif

      - name: Upload SARIF - Semgrep
        if: always()
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: ${{ steps.project.outputs.dir }}/reports/semgrep.sarif
          category: "/tool:semgrep/language:python"
        continue-on-error: true

      - name: Upload SARIF - Trivy deps
        if: always()
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: ${{ steps.project.outputs.dir }}/reports/trivy-deps.sarif
          category: "/tool:trivy-deps/language:python"
        continue-on-error: true

      - name: Upload SARIF - Trivy image
        if: always()
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: ${{ steps.project.outputs.dir }}/reports/trivy-image.sarif
          category: "/tool:trivy-image/language:python"
        continue-on-error: true

      - name: Upload SARIF - Gitleaks
        if: always()
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: ${{ steps.project.outputs.dir }}/reports/gitleaks.sarif
          category: "/tool:gitleaks/language:python"
        continue-on-error: true

      - name: Upload SARIF - TruffleHog
        if: always()
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: ${{ steps.project.outputs.dir }}/reports/trufflehog.sarif
          category: "/tool:trufflehog/language:python"
        continue-on-error: true

      - name: Upload SARIF - Safety
        if: always()
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: ${{ steps.project.outputs.dir }}/reports/safety.sarif
          category: "/tool:safety/language:python"
        continue-on-error: true

      - name: Upload SARIF - pip-audit
        if: always()
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: ${{ steps.project.outputs.dir }}/reports/pip-audit.sarif
          category: "/tool:pip-audit/language:python"
        continue-on-error: true

      - name: Upload SARIF - OWASP ZAP baseline
        if: always()
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: ${{ steps.project.outputs.dir }}/reports/zap-baseline.sarif
          category: "/tool:zap-baseline/language:python"
        continue-on-error: true

      - name: Upload SARIF - OWASP ZAP full
        if: always()
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: ${{ steps.project.outputs.dir }}/reports/zap-full.sarif
          category: "/tool:zap-full/language:python"
        continue-on-error: true

      - name: Build consolidated report summary
        if: always()
        shell: bash
        env:
          REPORT_DIR: ${{ steps.project.outputs.dir }}/reports
          ZAP_BASE_OUTCOME: ${{ steps.zap_baseline_step.outcome }}
          ZAP_FULL_OUTCOME: ${{ steps.zap_full_step.outcome }}
        run: |
          python - <<'PY'
          import json
          import os
          import re
          from collections import Counter
          from pathlib import Path

          report_dir = Path(os.environ["REPORT_DIR"])
          summary_path = report_dir / "summary.md"
          zap_base_outcome = os.environ.get("ZAP_BASE_OUTCOME", "").strip() or "unknown"
          zap_full_outcome = os.environ.get("ZAP_FULL_OUTCOME", "").strip() or "unknown"

          def read_text(name: str) -> str:
            path = report_dir / name
            if not path.exists():
              return ""
            return path.read_text(encoding="utf-8", errors="replace")

          def parse_sarif(name: str):
            raw = read_text(name)
            if not raw.strip():
              return None
            try:
              data = json.loads(raw)
            except json.JSONDecodeError:
              return None
            runs = data.get("runs", [])
            if not runs:
              return {"total": 0, "levels": {}}
            results = runs[0].get("results", [])
            rules = runs[0].get("tool", {}).get("driver", {}).get("rules", [])
            default_level = {r.get("id"): r.get("defaultConfiguration", {}).get("level") for r in rules}
            levels = Counter()
            severities = Counter()
            level_to_sev = {
              "error": "CRITICAL",
              "warning": "MEDIUM",
              "note": "LOW",
              "none": "LOW",
            }
            for item in results:
              lvl = item.get("level") or default_level.get(item.get("ruleId")) or "unknown"
              levels[lvl] += 1
              severities[level_to_sev.get(str(lvl).lower(), "LOW")] += 1
            return {"total": len(results), "levels": dict(sorted(levels.items())), "severities": dict(sorted(severities.items()))}

          def parse_trivy_severity(name: str):
            raw = read_text(name)
            if not raw.strip():
              return None
            try:
              data = json.loads(raw)
            except json.JSONDecodeError:
              return None
            runs = data.get("runs", [])
            if not runs:
              return None
            rules = runs[0].get("tool", {}).get("driver", {}).get("rules", [])
            results = runs[0].get("results", [])
            sev_by_rule = {}
            for rule in rules:
              rid = rule.get("id")
              tags = rule.get("properties", {}).get("tags", [])
              sev = None
              for t in tags:
                tt = str(t).upper()
                if tt in {"CRITICAL", "HIGH", "MEDIUM", "LOW"}:
                  sev = tt
                  break
              sev_by_rule[rid] = sev or "LOW"
            counts = Counter()
            for item in results:
              counts[sev_by_rule.get(item.get("ruleId"), "LOW")] += 1
            return dict(sorted(counts.items()))

          def parse_safety():
            raw_text = read_text("safety.txt")
            raw_json = read_text("safety.json")
            if raw_json:
              try:
                data = json.loads(raw_json)
                if isinstance(data, dict):
                  vulns = data.get("vulnerabilities")
                  if isinstance(vulns, list):
                    return {"total": str(len(vulns))}
              except json.JSONDecodeError:
                pass
            if not raw_text:
              return None
            # Strip ANSI sequences from Safety text output for robust parsing.
            cleaned = re.sub(r"\x1b\[[0-9;]*m", "", raw_text)
            m = re.search(r"(\d+)\s+vulnerabilities found", cleaned, flags=re.IGNORECASE)
            total = m.group(1) if m else "N/A"
            return {"total": total}

          def parse_trufflehog():
            path = report_dir / "trufflehog.json"
            if not path.exists():
              return None
            findings = 0
            for line in path.read_text(encoding="utf-8", errors="replace").splitlines():
              line = line.strip()
              if not line:
                continue
              try:
                obj = json.loads(line)
                if isinstance(obj, dict):
                  findings += 1
              except json.JSONDecodeError:
                pass
            return {"total": findings}

          def parse_pip_audit():
            path = report_dir / "pip-audit.json"
            if not path.exists():
              return None
            raw = path.read_text(encoding="utf-8", errors="replace").strip()
            if not raw:
              return None
            try:
              data = json.loads(raw)
            except json.JSONDecodeError:
              return None
            if isinstance(data, dict) and data.get("message"):
              return {"missing": True, "message": data.get("message", "report missing")}
            deps = []
            if isinstance(data, list):
              deps = data
            elif isinstance(data, dict):
              deps = data.get("dependencies", [])
            vuln_count = 0
            ids = set()
            for dep in deps:
              vulns = dep.get("vulns") or dep.get("vulnerabilities") or []
              vuln_count += len(vulns)
              for v in vulns:
                vid = v.get("id") or v.get("alias")
                if vid:
                  ids.add(str(vid))
            return {"dependencies": len(deps), "vulnerabilities": vuln_count, "unique_ids": len(ids)}

          def parse_zap(name: str):
            path = report_dir / name
            if not path.exists():
              return {"status": "missing", "message": "report missing"}
            raw = path.read_text(encoding="utf-8", errors="replace").strip()
            if not raw:
              return {"status": "missing", "message": "report missing"}
            try:
              data = json.loads(raw)
            except json.JSONDecodeError:
              return {"status": "available"}
            if isinstance(data, dict) and data.get("status") == "missing":
              return {"status": "missing", "message": data.get("message", "report missing")}
            sites = data.get("site", []) if isinstance(data, dict) else []
            risk_map = {"0": "info", "1": "low", "2": "medium", "3": "high"}
            alert_type_counts = Counter()
            instance_counts = Counter()
            alert_types_total = 0
            instances_total = 0
            for site in sites:
              for alert in site.get("alerts", []):
                risk = risk_map.get(str(alert.get("riskcode", "")), "unknown")
                instances = alert.get("instances") or []
                n = len(instances) if instances else 1
                alert_type_counts[risk] += 1
                instance_counts[risk] += n
                alert_types_total += 1
                instances_total += n
            ordered = ["high", "medium", "low", "info", "unknown"]
            alert_types_levels = {k: int(alert_type_counts.get(k, 0)) for k in ordered}
            instance_levels = {k: int(instance_counts.get(k, 0)) for k in ordered}
            return {
              "status": "available",
              "alert_types": alert_types_total,
              "instances": instances_total,
              "levels_alert_types": alert_types_levels,
              "levels_instances": instance_levels,
            }

          semgrep = parse_sarif("semgrep.sarif")
          trivy_deps = parse_sarif("trivy-deps.sarif")
          trivy_image = parse_sarif("trivy-image.sarif")
          gitleaks = parse_sarif("gitleaks.sarif")
          safety = parse_safety()
          trufflehog = parse_trufflehog()
          pip_audit = parse_pip_audit()
          zap_baseline = parse_zap("zap-baseline-report.json")
          zap_full = parse_zap("zap-report.json")
          trivy_deps_sev = parse_trivy_severity("trivy-deps.sarif")
          trivy_image_sev = parse_trivy_severity("trivy-image.sarif")

          def fmt_levels(obj):
            if not obj or not obj.get("levels"):
              return "-"
            return ", ".join(f"{k}:{v}" for k, v in obj["levels"].items())

          def fmt_sev(obj):
            if not obj or not obj.get("severities"):
              return "-"
            order = ["CRITICAL", "HIGH", "MEDIUM", "LOW"]
            return ", ".join(f"{k}:{obj['severities'][k]}" for k in order if k in obj["severities"])

          def fmt_zap_levels(levels: dict) -> str:
            order = ["high", "medium", "low", "info", "unknown"]
            return ", ".join(f"{k}:{int(levels.get(k, 0))}" for k in order)

          def fmt_zap(obj, outcome: str) -> str:
            if obj and obj.get("status") == "available":
              return (
                f"report=available; alert_types={obj.get('alert_types', 'N/A')}; "
                f"instances={obj.get('instances', 'N/A')}; "
                f"levels(alert_types)={fmt_zap_levels(obj.get('levels_alert_types', {}))}; "
                f"levels(instances)={fmt_zap_levels(obj.get('levels_instances', {}))}; "
                f"step={outcome}"
              )
            if obj:
              return f"status={obj.get('status', 'missing')}; step={outcome}; {obj.get('message', 'report missing')}"
            return f"status=missing; step={outcome}; report missing"

          lines = [
            "# DevSecOps Report Summary",
            "",
            "| Tool | Key Results |",
            "|---|---|",
            f"| Safety | vulnerabilities={safety['total'] if safety else 'N/A'} |",
            f"| pip-audit | " + (
              f"dependencies={pip_audit['dependencies']}; vulnerabilities={pip_audit['vulnerabilities']}; advisories={pip_audit['unique_ids']}" if pip_audit and not pip_audit.get('missing')
              else (pip_audit.get('message', 'N/A') if pip_audit else 'N/A')
            ) + " |",
            f"| OWASP ZAP Baseline (DAST) | {fmt_zap(zap_baseline, zap_base_outcome)} |",
            f"| OWASP ZAP Full (active) | {fmt_zap(zap_full, zap_full_outcome)} |",
            f"| Semgrep (SARIF) | findings={semgrep['total'] if semgrep else 'N/A'}; levels={fmt_levels(semgrep)}; severities={fmt_sev(semgrep)} |",
            f"| Trivy deps (SARIF) | findings={trivy_deps['total'] if trivy_deps else 'N/A'}; levels={fmt_levels(trivy_deps)}; severities={', '.join([f'{k}:{v}' for k,v in (trivy_deps_sev or {}).items()]) if trivy_deps_sev else 'N/A'} |",
            f"| Trivy image (SARIF) | findings={trivy_image['total'] if trivy_image else 'N/A'}; levels={fmt_levels(trivy_image)}; severities={', '.join([f'{k}:{v}' for k,v in (trivy_image_sev or {}).items()]) if trivy_image_sev else 'N/A'} |",
            f"| Gitleaks (SARIF) | findings={gitleaks['total'] if gitleaks else 'N/A'}; levels={fmt_levels(gitleaks)}; severities={fmt_sev(gitleaks)} |",
            f"| TruffleHog (JSON) | findings={trufflehog['total'] if trufflehog else 'N/A'} |",
            "",
            "## Files",
            "",
          ]

          for p in sorted(report_dir.glob("**/*")):
            if p.is_file():
              rel = p.relative_to(report_dir)
              lines.append(f"- `{rel.as_posix()}`")

          summary_path.write_text("\n".join(lines) + "\n", encoding="utf-8")
          print(summary_path.read_text(encoding="utf-8"))
          PY

      - name: Publish summary to workflow run
        if: always()
        shell: bash
        run: |
          cat "${{ steps.project.outputs.dir }}/reports/summary.md" >> "$GITHUB_STEP_SUMMARY"

      - name: Upload reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: devsecops-reports
          path: ${{ steps.project.outputs.dir }}/reports
