name: DevSecOps Pipeline

on:
  push:
    branches:
      - main
    paths:
      - "python/**"
      - ".github/workflows/python-devsecops.yml"
  pull_request:
    branches:
      - main
    paths:
      - "python/**"
      - ".github/workflows/python-devsecops.yml"
  workflow_dispatch:

permissions:
  contents: read
  actions: read

jobs:
  devsecops:
    if: github.actor != 'dependabot[bot]'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout source
        uses: actions/checkout@v4

      - name: Detect project directory
        id: project
        shell: bash
        run: |
          if [ -f "python/manage.py" ]; then
            echo "dir=python" >> "$GITHUB_OUTPUT"
          else
            echo "Could not find python/manage.py"
            exit 1
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Create report directories
        shell: bash
        run: |
          mkdir -p "${{ steps.project.outputs.dir }}/reports"

      - name: Secrets scan - Gitleaks (SARIF)
        shell: bash
        run: |
          docker run --rm -v "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}:/repo" zricethezav/gitleaks:latest detect \
            --source="/repo" \
            --report-format sarif \
            --report-path "/repo/reports/gitleaks.sarif" \
            --exit-code 0
        continue-on-error: true

      - name: Secrets scan - TruffleHog (JSON)
        shell: bash
        run: |
          docker run --rm -v "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}:/repo" trufflesecurity/trufflehog:latest filesystem \
            --directory=/repo \
            --json > "${{ steps.project.outputs.dir }}/reports/trufflehog.json" || true
          if [ ! -s "${{ steps.project.outputs.dir }}/reports/trufflehog.json" ]; then
            echo "[]" > "${{ steps.project.outputs.dir }}/reports/trufflehog.json"
          fi
        continue-on-error: true

      - name: Install application and security tooling
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install flake8 pylint "safety<3" semgrep
          pip install --upgrade pip-audit
          python - <<'PY'
          import importlib.util
          import subprocess
          import sys

          # Some runner environments resolve an incompatible cyclonedx library.
          # pip-audit imports `cyclonedx.parser`, so ensure that module exists.
          if importlib.util.find_spec("cyclonedx.parser") is None:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "cyclonedx-python-lib<4"])
          PY

      - name: Lint - flake8
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          set -o pipefail
          flake8 . --statistics --count | tee reports/flake8.txt
        continue-on-error: true

      - name: SAST - pylint
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          set -o pipefail
          pylint challenge introduction pygoat manage.py --exit-zero | tee reports/pylint.txt

      - name: Unit tests (unittest via Django test runner)
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          set -o pipefail
          python manage.py test --verbosity 2 | tee reports/unit-tests.txt

      - name: SCA - Safety
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          safety check -r requirements.txt --full-report --json > reports/safety.json || true
          safety check -r requirements.txt --full-report > reports/safety.txt || true
          if [ ! -s reports/safety.json ]; then
            echo '{"status":"missing","message":"Safety JSON output was not generated; see safety.txt for full details."}' > reports/safety.json
          fi
        continue-on-error: true

      - name: SCA - pip-audit
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          set +e
          python -m pip show pip-audit cyclonedx-python-lib > reports/pip-audit-env.txt 2>&1
          python - <<'PY' >> reports/pip-audit-env.txt 2>&1
          import importlib.util
          print("cyclonedx.parser module found:", bool(importlib.util.find_spec("cyclonedx.parser")))
          PY
          python -m pip_audit -r requirements.txt --format json --output reports/pip-audit.json > reports/pip-audit-json.log 2>&1
          python -m pip_audit -r requirements.txt > reports/pip-audit.txt 2>&1
          # If text output is empty, preserve JSON-run logs for troubleshooting.
          if [ ! -s reports/pip-audit.txt ] && [ -s reports/pip-audit-json.log ]; then
            cp reports/pip-audit-json.log reports/pip-audit.txt
          fi
          if [ ! -s reports/pip-audit.json ]; then
            echo '{"dependencies":[],"vulnerabilities":[],"message":"pip-audit JSON output was not generated; see pip-audit.txt for details."}' > reports/pip-audit.json
          fi
          exit 0
        continue-on-error: true

      - name: SAST - Semgrep (SARIF)
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          semgrep scan --config auto --sarif --output reports/semgrep.sarif .
        continue-on-error: true

      - name: SCA - Trivy filesystem scan (Python dependencies)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: fs
          scan-ref: ${{ steps.project.outputs.dir }}
          vuln-type: library
          severity: CRITICAL,HIGH,MEDIUM
          format: sarif
          output: ${{ steps.project.outputs.dir }}/reports/trivy-deps.sarif
        continue-on-error: true

      - name: Build Docker image
        run: docker build -t pygoat:ci -f ${{ steps.project.outputs.dir }}/Dockerfile ${{ steps.project.outputs.dir }}

      - name: Container scan - Trivy image (human-readable)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: pygoat:ci
          vuln-type: os,library
          severity: CRITICAL,HIGH,MEDIUM
          format: table
          output: ${{ steps.project.outputs.dir }}/reports/trivy-image.txt
        continue-on-error: true

      - name: Container scan - Trivy image (SARIF)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: pygoat:ci
          vuln-type: os,library
          severity: CRITICAL,HIGH,MEDIUM
          format: sarif
          output: ${{ steps.project.outputs.dir }}/reports/trivy-image.sarif
        continue-on-error: true

      - name: Start app container for DAST
        run: |
          docker network create zap-net || true
          docker run -d --name pygoat-app -p 8000:8000 --network zap-net \
            pygoat:ci \
            sh -c "python manage.py migrate --noinput && gunicorn --bind 0.0.0.0:8000 --workers 3 --threads 2 --timeout 60 pygoat.wsgi:application"
          for i in {1..45}; do
            if docker run --rm --network zap-net curlimages/curl:8.10.1 -fsS http://pygoat-app:8000/ > /dev/null; then
              echo "App is reachable for ZAP."
              exit 0
            fi
            sleep 2
          done
          echo "App did not become ready in time. Container logs:"
          docker logs pygoat-app || true
          exit 1

      # OWASP ZAP baseline: DAST scan against a live running app endpoint.
      - name: DAST - OWASP ZAP baseline scan
        run: |
          chmod -R 777 "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}/reports" || true
          docker run --rm --network zap-net \
            --user root \
            -v "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}/reports:/zap/wrk/:rw" \
            ghcr.io/zaproxy/zaproxy:stable zap-baseline.py \
            -t http://pygoat-app:8000 \
            -r zap-report.html \
            -J zap-report.json \
            -x zap-report.xml \
            -w zap-warnings.md \
            -I
        continue-on-error: true

      - name: Normalize ZAP artifacts
        if: always()
        shell: bash
        env:
          REPORT_DIR: ${{ steps.project.outputs.dir }}/reports
        run: |
          if [ ! -f "$REPORT_DIR/zap-report.html" ]; then
            cat > "$REPORT_DIR/zap-report.html" <<'EOF'
          <html><body><h1>ZAP report missing</h1><p>ZAP did not generate this report in this run. Check the DAST step logs.</p></body></html>
          EOF
          fi
          if [ ! -f "$REPORT_DIR/zap-report.json" ]; then
            cat > "$REPORT_DIR/zap-report.json" <<'EOF'
          {"status":"missing","message":"ZAP did not generate JSON report in this run. Check the DAST step logs."}
          EOF
          fi
          if [ ! -f "$REPORT_DIR/zap-report.xml" ]; then
            cat > "$REPORT_DIR/zap-report.xml" <<'EOF'
          <report status="missing" message="ZAP did not generate XML report in this run. Check the DAST step logs."/>
          EOF
          fi
          if [ ! -f "$REPORT_DIR/zap-warnings.md" ]; then
            cat > "$REPORT_DIR/zap-warnings.md" <<'EOF'
          # ZAP warnings
          ZAP warnings report was not generated in this run.
          EOF
          fi

      - name: Stop app container
        if: always()
        run: |
          docker rm -f pygoat-app || true
          docker network rm zap-net || true

      - name: Build consolidated report summary
        if: always()
        shell: bash
        env:
          REPORT_DIR: ${{ steps.project.outputs.dir }}/reports
        run: |
          python - <<'PY'
          import json
          import os
          import re
          from collections import Counter
          from pathlib import Path

          report_dir = Path(os.environ["REPORT_DIR"])
          summary_path = report_dir / "summary.md"

          def read_text(name: str) -> str:
            path = report_dir / name
            if not path.exists():
              return ""
            return path.read_text(encoding="utf-8", errors="replace")

          def parse_sarif(name: str):
            raw = read_text(name)
            if not raw.strip():
              return None
            try:
              data = json.loads(raw)
            except json.JSONDecodeError:
              return None
            runs = data.get("runs", [])
            if not runs:
              return {"total": 0, "levels": {}}
            results = runs[0].get("results", [])
            rules = runs[0].get("tool", {}).get("driver", {}).get("rules", [])
            default_level = {r.get("id"): r.get("defaultConfiguration", {}).get("level") for r in rules}
            levels = Counter()
            severities = Counter()
            level_to_sev = {
              "error": "HIGH",
              "warning": "MEDIUM",
              "note": "LOW",
              "none": "LOW",
            }
            for item in results:
              lvl = item.get("level") or default_level.get(item.get("ruleId")) or "unknown"
              levels[lvl] += 1
              severities[level_to_sev.get(str(lvl).lower(), "UNKNOWN")] += 1
            return {"total": len(results), "levels": dict(sorted(levels.items())), "severities": dict(sorted(severities.items()))}

          def parse_trivy_severity(name: str):
            raw = read_text(name)
            if not raw.strip():
              return None
            try:
              data = json.loads(raw)
            except json.JSONDecodeError:
              return None
            runs = data.get("runs", [])
            if not runs:
              return None
            rules = runs[0].get("tool", {}).get("driver", {}).get("rules", [])
            results = runs[0].get("results", [])
            sev_by_rule = {}
            for rule in rules:
              rid = rule.get("id")
              tags = rule.get("properties", {}).get("tags", [])
              sev = None
              for t in tags:
                tt = str(t).upper()
                if tt in {"CRITICAL", "HIGH", "MEDIUM", "LOW", "UNKNOWN"}:
                  sev = tt
                  break
              sev_by_rule[rid] = sev or "UNKNOWN"
            counts = Counter()
            for item in results:
              counts[sev_by_rule.get(item.get("ruleId"), "UNKNOWN")] += 1
            return dict(sorted(counts.items()))

          def parse_flake8():
            raw = read_text("flake8.txt")
            if not raw:
              return None
            lines = [x for x in raw.splitlines() if x.strip()]
            counts = Counter()
            for ln in lines:
              m = re.search(r":\s*([A-Z]\d{3})\b", ln)
              if m:
                counts[m.group(1)] += 1
            top = ", ".join(f"{k}:{v}" for k, v in counts.most_common(8))
            return {"total": len(lines), "top": top}

          def parse_pylint():
            raw = read_text("pylint.txt")
            if not raw:
              return None
            m = re.search(r"rated at\s+([0-9.]+)/10", raw)
            score = m.group(1) if m else "N/A"
            return {"score": score}

          def parse_safety():
            raw_text = read_text("safety.txt")
            raw_json = read_text("safety.json")
            if raw_json:
              try:
                data = json.loads(raw_json)
                if isinstance(data, dict):
                  vulns = data.get("vulnerabilities")
                  if isinstance(vulns, list):
                    return {"total": str(len(vulns))}
              except json.JSONDecodeError:
                pass
            if not raw_text:
              return None
            # Strip ANSI sequences from Safety text output for robust parsing.
            cleaned = re.sub(r"\x1b\[[0-9;]*m", "", raw_text)
            m = re.search(r"(\d+)\s+vulnerabilities found", cleaned, flags=re.IGNORECASE)
            total = m.group(1) if m else "N/A"
            return {"total": total}

          def parse_tests():
            raw = read_text("unit-tests.txt")
            if not raw:
              return None
            m = re.search(r"Found\s+(\d+)\s+test\(s\)", raw)
            total = m.group(1) if m else "N/A"
            return {"total": total}

          def parse_trufflehog():
            path = report_dir / "trufflehog.json"
            if not path.exists():
              return None
            findings = 0
            for line in path.read_text(encoding="utf-8", errors="replace").splitlines():
              line = line.strip()
              if not line:
                continue
              try:
                obj = json.loads(line)
                if isinstance(obj, dict):
                  findings += 1
              except json.JSONDecodeError:
                pass
            return {"total": findings}

          def parse_pip_audit():
            path = report_dir / "pip-audit.json"
            if not path.exists():
              return None
            raw = path.read_text(encoding="utf-8", errors="replace").strip()
            if not raw:
              return None
            try:
              data = json.loads(raw)
            except json.JSONDecodeError:
              return None
            if isinstance(data, dict) and data.get("message"):
              return {"missing": True, "message": data.get("message", "report missing")}
            deps = []
            if isinstance(data, list):
              deps = data
            elif isinstance(data, dict):
              deps = data.get("dependencies", [])
            vuln_count = 0
            ids = set()
            for dep in deps:
              vulns = dep.get("vulns") or dep.get("vulnerabilities") or []
              vuln_count += len(vulns)
              for v in vulns:
                vid = v.get("id") or v.get("alias")
                if vid:
                  ids.add(str(vid))
            return {"dependencies": len(deps), "vulnerabilities": vuln_count, "unique_ids": len(ids)}

          def parse_zap():
            path = report_dir / "zap-report.json"
            if not path.exists():
              return None
            raw = path.read_text(encoding="utf-8", errors="replace").strip()
            if not raw:
              return None
            try:
              data = json.loads(raw)
            except json.JSONDecodeError:
              return {"status": "available"}
            if isinstance(data, dict) and data.get("status") == "missing":
              return {"status": "missing", "message": data.get("message", "report missing")}
            sites = data.get("site", []) if isinstance(data, dict) else []
            counts = Counter()
            total = 0
            risk_map = {"0": "info", "1": "low", "2": "medium", "3": "high"}
            for site in sites:
              for alert in site.get("alerts", []):
                risk = risk_map.get(str(alert.get("riskcode", "")), "unknown")
                instances = alert.get("instances") or []
                n = len(instances) if instances else 1
                counts[risk] += n
                total += n
            return {"status": "available", "alerts": total, "levels": dict(sorted(counts.items()))}

          semgrep = parse_sarif("semgrep.sarif")
          trivy_deps = parse_sarif("trivy-deps.sarif")
          trivy_image = parse_sarif("trivy-image.sarif")
          gitleaks = parse_sarif("gitleaks.sarif")
          flake8 = parse_flake8()
          pylint = parse_pylint()
          safety = parse_safety()
          tests = parse_tests()
          trufflehog = parse_trufflehog()
          pip_audit = parse_pip_audit()
          zap = parse_zap()
          trivy_deps_sev = parse_trivy_severity("trivy-deps.sarif")
          trivy_image_sev = parse_trivy_severity("trivy-image.sarif")

          def fmt_levels(obj):
            if not obj or not obj.get("levels"):
              return "-"
            return ", ".join(f"{k}:{v}" for k, v in obj["levels"].items())

          def fmt_sev(obj):
            if not obj or not obj.get("severities"):
              return "-"
            order = ["CRITICAL", "HIGH", "MEDIUM", "LOW", "UNKNOWN"]
            return ", ".join(f"{k}:{obj['severities'][k]}" for k in order if k in obj["severities"])

          lines = [
            "# DevSecOps Report Summary",
            "",
            "| Tool | Key Results |",
            "|---|---|",
            f"| Unit tests | discovered={tests['total'] if tests else 'N/A'} |",
            f"| Flake8 | issues={flake8['total'] if flake8 else 'N/A'}; top={flake8['top'] if flake8 else '-'} |",
            f"| Pylint | score={pylint['score'] if pylint else 'N/A'}/10 |",
            f"| Safety | vulnerabilities={safety['total'] if safety else 'N/A'} |",
            f"| pip-audit | " + (
              f"dependencies={pip_audit['dependencies']}; vulnerabilities={pip_audit['vulnerabilities']}; advisories={pip_audit['unique_ids']}" if pip_audit and not pip_audit.get('missing')
              else (pip_audit.get('message', 'N/A') if pip_audit else 'N/A')
            ) + " |",
            f"| OWASP ZAP (DAST) | " + (
              f"report=available; alerts={zap.get('alerts', 'N/A')}; levels={fmt_levels(zap)}" if zap and zap.get("status") == "available"
              else (zap.get("message", "report missing") if zap else "N/A")
            ) + " |",
            f"| Semgrep (SARIF) | findings={semgrep['total'] if semgrep else 'N/A'}; levels={fmt_levels(semgrep)}; severities={fmt_sev(semgrep)} |",
            f"| Trivy deps (SARIF) | findings={trivy_deps['total'] if trivy_deps else 'N/A'}; levels={fmt_levels(trivy_deps)}; severities={', '.join([f'{k}:{v}' for k,v in (trivy_deps_sev or {}).items()]) if trivy_deps_sev else 'N/A'} |",
            f"| Trivy image (SARIF) | findings={trivy_image['total'] if trivy_image else 'N/A'}; levels={fmt_levels(trivy_image)}; severities={', '.join([f'{k}:{v}' for k,v in (trivy_image_sev or {}).items()]) if trivy_image_sev else 'N/A'} |",
            f"| Gitleaks (SARIF) | findings={gitleaks['total'] if gitleaks else 'N/A'}; levels={fmt_levels(gitleaks)}; severities={fmt_sev(gitleaks)} |",
            f"| TruffleHog (JSON) | findings={trufflehog['total'] if trufflehog else 'N/A'} |",
            "",
            "## Files",
            "",
          ]

          for p in sorted(report_dir.glob("**/*")):
            if p.is_file():
              rel = p.relative_to(report_dir)
              lines.append(f"- `{rel.as_posix()}`")

          summary_path.write_text("\n".join(lines) + "\n", encoding="utf-8")
          print(summary_path.read_text(encoding="utf-8"))
          PY

      - name: Publish summary to workflow run
        if: always()
        shell: bash
        run: |
          cat "${{ steps.project.outputs.dir }}/reports/summary.md" >> "$GITHUB_STEP_SUMMARY"

      - name: Upload reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: devsecops-reports
          path: ${{ steps.project.outputs.dir }}/reports
