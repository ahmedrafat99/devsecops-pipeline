name: DevSecOps Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:

permissions:
  contents: read
  actions: read

jobs:
  devsecops:
    if: github.actor != 'dependabot[bot]'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout source
        uses: actions/checkout@v4

      - name: Detect project directory
        id: project
        shell: bash
        run: |
          if [ -f "python/pygoat_flat/manage.py" ]; then
            echo "dir=python/pygoat_flat" >> "$GITHUB_OUTPUT"
          elif [ -f "python/pygoat/manage.py" ]; then
            echo "dir=python/pygoat" >> "$GITHUB_OUTPUT"
          elif [ -f "manage.py" ]; then
            echo "dir=." >> "$GITHUB_OUTPUT"
          else
            echo "Could not find manage.py in expected locations"
            exit 1
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up Java (required by Dependency-Check)
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "17"

      - name: Create report directories
        shell: bash
        run: |
          mkdir -p "${{ steps.project.outputs.dir }}/reports"
          mkdir -p "${{ steps.project.outputs.dir }}/reports/dependency-check"
          mkdir -p "${RUNNER_TEMP}/dependency-check-data"

      - name: Cache Dependency-Check data
        uses: actions/cache@v4
        with:
          path: ${{ runner.temp }}/dependency-check-data
          key: dependency-check-db-${{ runner.os }}-${{ hashFiles('python/pygoat_flat/requirements.txt', 'python/pygoat/requirements.txt', 'requirements.txt') }}
          restore-keys: |
            dependency-check-db-${{ runner.os }}-

      - name: Secrets scan - Gitleaks (SARIF)
        shell: bash
        run: |
          docker run --rm -v "${GITHUB_WORKSPACE}:/repo" zricethezav/gitleaks:latest detect \
            --source="/repo" \
            --report-format sarif \
            --report-path "/repo/${{ steps.project.outputs.dir }}/reports/gitleaks.sarif" \
            --exit-code 0
        continue-on-error: true

      - name: Secrets scan - TruffleHog (JSON)
        shell: bash
        run: |
          docker run --rm -v "${GITHUB_WORKSPACE}:/pwd" trufflesecurity/trufflehog:latest filesystem \
            --directory=/pwd \
            --json \
            > "${{ steps.project.outputs.dir }}/reports/trufflehog.json" || true
        continue-on-error: true

      - name: Install application and security tooling
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install flake8 pylint "safety<3" semgrep

      - name: Lint - flake8
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          set -o pipefail
          flake8 . --statistics --count | tee reports/flake8.txt
        continue-on-error: true

      - name: SAST - pylint
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          set -o pipefail
          pylint challenge introduction pygoat manage.py --exit-zero | tee reports/pylint.txt

      - name: Unit tests (unittest via Django test runner)
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          set -o pipefail
          python manage.py test --verbosity 2 | tee reports/unit-tests.txt

      # OWASP Dependency-Check: SCA scanner for third-party package CVEs.
      - name: SCA - Dependency-Check DB update
        timeout-minutes: 20
        shell: bash
        env:
          NVD_API_KEY: ${{ secrets.NVD_API_KEY }}
        run: |
          set -euo pipefail
          REPORT_DIR="${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}/reports/dependency-check"
          mkdir -p "$REPORT_DIR"
          UPDATE_LOG="$REPORT_DIR/dependency-check-update.log"
          rm -f "$UPDATE_LOG"

          API_ARG=()
          if [ -n "${NVD_API_KEY:-}" ]; then
            echo "[dependency-check] Using NVD API key for faster DB update."
            API_ARG+=(--nvdApiKey "$NVD_API_KEY")
          else
            echo "[dependency-check] NVD_API_KEY is not set; first update may be slow."
          fi

          docker run --rm \
            -v "${RUNNER_TEMP}/dependency-check-data:/usr/share/dependency-check/data:rw" \
            -v "${REPORT_DIR}:/report:rw" \
            owasp/dependency-check:latest \
            --updateonly \
            --nvdValidForHours 24 \
            "${API_ARG[@]}" \
            --log /report/dependency-check-update.log &
          DC_PID=$!

          while kill -0 "$DC_PID" 2>/dev/null; do
            echo "[dependency-check] DB update still running..."
            if [ -f "$UPDATE_LOG" ]; then
              tail -n 5 "$UPDATE_LOG" || true
            fi
            sleep 30
          done
          wait "$DC_PID" || true
        continue-on-error: true

      - name: SCA - OWASP Dependency-Check
        timeout-minutes: 25
        shell: bash
        env:
          NVD_API_KEY: ${{ secrets.NVD_API_KEY }}
        run: |
          set -euo pipefail
          # Scan only dependency manifests and reuse warmed local DB for reliability.
          REPORT_DIR="${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}/reports/dependency-check"
          SCAN_LOG="$REPORT_DIR/dependency-check.log"
          rm -f "$SCAN_LOG"
          DATA_DIR="${RUNNER_TEMP}/dependency-check-data"

          DC_ARGS=(
            --scan /src/requirements.txt
            --project "pygoat"
            --format "HTML"
            --format "JSON"
            --format "JUNIT"
            --out /report
            --log /report/dependency-check.log
            --nvdValidForHours 24
            --enableRetired
          )

          if find "$DATA_DIR" -type f \( -name "*.mv.db" -o -name "*.db" \) | grep -q .; then
            echo "[dependency-check] Existing DB found; running with --noupdate."
            DC_ARGS+=(--noupdate)
          else
            echo "[dependency-check] No local DB found; scan will perform update."
          fi

          if [ -n "${NVD_API_KEY:-}" ]; then
            DC_ARGS+=(--nvdApiKey "$NVD_API_KEY")
          fi

          docker run --rm \
            -v "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}:/src:rw" \
            -v "${REPORT_DIR}:/report:rw" \
            -v "${RUNNER_TEMP}/dependency-check-data:/usr/share/dependency-check/data:rw" \
            owasp/dependency-check:latest \
            "${DC_ARGS[@]}" &
          DC_PID=$!

          while kill -0 "$DC_PID" 2>/dev/null; do
            echo "[dependency-check] Scan still running..."
            if [ -f "$SCAN_LOG" ]; then
              tail -n 5 "$SCAN_LOG" || true
            fi
            sleep 30
          done
          wait "$DC_PID" || true
        continue-on-error: true

      - name: Normalize Dependency-Check artifacts
        if: always()
        shell: bash
        env:
          REPORT_DIR: ${{ steps.project.outputs.dir }}/reports
        run: |
          mkdir -p "$REPORT_DIR/dependency-check"
          if [ ! -f "$REPORT_DIR/dependency-check/dependency-check-report.html" ]; then
            cat > "$REPORT_DIR/dependency-check/dependency-check-report.html" <<'EOF'
          <html><body><h1>Dependency-Check report missing</h1><p>Dependency-Check did not generate HTML output in this run. Check the SCA step logs.</p></body></html>
          EOF
          fi
          if [ ! -f "$REPORT_DIR/dependency-check/dependency-check-report.json" ]; then
            cat > "$REPORT_DIR/dependency-check/dependency-check-report.json" <<'EOF'
          {"status":"missing","message":"Dependency-Check did not generate JSON output in this run. Check the SCA step logs."}
          EOF
          fi
          if [ ! -f "$REPORT_DIR/dependency-check/dependency-check-report.junit.xml" ]; then
            cat > "$REPORT_DIR/dependency-check/dependency-check-report.junit.xml" <<'EOF'
          <testsuites><testsuite name="dependency-check" tests="1" failures="1"><testcase classname="dependency-check" name="report-generation"><failure message="Dependency-Check JUnit report missing">Dependency-Check did not generate JUnit output in this run. Check the SCA step logs.</failure></testcase></testsuite></testsuites>
          EOF
          fi

      - name: SCA - Safety
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          safety check -r requirements.txt --full-report --json > reports/safety.json || true
          safety check -r requirements.txt --full-report > reports/safety.txt || true
          if [ ! -s reports/safety.json ]; then
            echo '{"status":"missing","message":"Safety JSON output was not generated; see safety.txt for full details."}' > reports/safety.json
          fi
        continue-on-error: true

      - name: SAST - Semgrep (SARIF)
        working-directory: ${{ steps.project.outputs.dir }}
        run: |
          semgrep scan --config auto --sarif --output reports/semgrep.sarif .
        continue-on-error: true

      - name: SCA - Trivy filesystem scan (Python dependencies)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: fs
          scan-ref: ${{ steps.project.outputs.dir }}
          vuln-type: library
          severity: CRITICAL,HIGH,MEDIUM
          format: sarif
          output: ${{ steps.project.outputs.dir }}/reports/trivy-deps.sarif
        continue-on-error: true

      - name: Build Docker image
        run: docker build -t pygoat:ci -f ${{ steps.project.outputs.dir }}/Dockerfile ${{ steps.project.outputs.dir }}

      - name: Container scan - Trivy image (human-readable)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: pygoat:ci
          vuln-type: os,library
          severity: CRITICAL,HIGH,MEDIUM
          format: table
          output: ${{ steps.project.outputs.dir }}/reports/trivy-image.txt
        continue-on-error: true

      - name: Container scan - Trivy image (SARIF)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: pygoat:ci
          vuln-type: os,library
          severity: CRITICAL,HIGH,MEDIUM
          format: sarif
          output: ${{ steps.project.outputs.dir }}/reports/trivy-image.sarif
        continue-on-error: true

      - name: Start app container for DAST
        run: |
          docker network create zap-net || true
          docker run -d --name pygoat-app -p 8000:8000 --network zap-net \
            pygoat:ci \
            sh -c "python manage.py migrate --noinput && gunicorn --bind 0.0.0.0:8000 --workers 3 --threads 2 --timeout 60 pygoat.wsgi:application"
          for i in {1..45}; do
            if docker run --rm --network zap-net curlimages/curl:8.10.1 -fsS http://pygoat-app:8000/ > /dev/null; then
              echo "App is reachable for ZAP."
              exit 0
            fi
            sleep 2
          done
          echo "App did not become ready in time. Container logs:"
          docker logs pygoat-app || true
          exit 1

      # OWASP ZAP baseline: DAST scan against a live running app endpoint.
      - name: DAST - OWASP ZAP baseline scan
        run: |
          chmod -R 777 "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}/reports" || true
          docker run --rm --network zap-net \
            --user root \
            -v "${GITHUB_WORKSPACE}/${{ steps.project.outputs.dir }}/reports:/zap/wrk/:rw" \
            ghcr.io/zaproxy/zaproxy:stable zap-baseline.py \
            -t http://pygoat-app:8000 \
            -r zap-report.html \
            -J zap-report.json \
            -x zap-report.xml \
            -w zap-warnings.md \
            -I
        continue-on-error: true

      - name: Normalize ZAP artifacts
        if: always()
        shell: bash
        env:
          REPORT_DIR: ${{ steps.project.outputs.dir }}/reports
        run: |
          if [ ! -f "$REPORT_DIR/zap-report.html" ]; then
            cat > "$REPORT_DIR/zap-report.html" <<'EOF'
          <html><body><h1>ZAP report missing</h1><p>ZAP did not generate this report in this run. Check the DAST step logs.</p></body></html>
          EOF
          fi
          if [ ! -f "$REPORT_DIR/zap-report.json" ]; then
            cat > "$REPORT_DIR/zap-report.json" <<'EOF'
          {"status":"missing","message":"ZAP did not generate JSON report in this run. Check the DAST step logs."}
          EOF
          fi
          if [ ! -f "$REPORT_DIR/zap-report.xml" ]; then
            cat > "$REPORT_DIR/zap-report.xml" <<'EOF'
          <report status="missing" message="ZAP did not generate XML report in this run. Check the DAST step logs."/>
          EOF
          fi
          if [ ! -f "$REPORT_DIR/zap-warnings.md" ]; then
            cat > "$REPORT_DIR/zap-warnings.md" <<'EOF'
          # ZAP warnings
          ZAP warnings report was not generated in this run.
          EOF
          fi

      - name: Stop app container
        if: always()
        run: |
          docker rm -f pygoat-app || true
          docker network rm zap-net || true

      - name: Build consolidated report summary
        if: always()
        shell: bash
        env:
          REPORT_DIR: ${{ steps.project.outputs.dir }}/reports
        run: |
          python - <<'PY'
          import json
          import os
          import re
          from collections import Counter
          from pathlib import Path

          report_dir = Path(os.environ["REPORT_DIR"])
          summary_path = report_dir / "summary.md"

          def read_text(name: str) -> str:
            path = report_dir / name
            if not path.exists():
              return ""
            return path.read_text(encoding="utf-8", errors="replace")

          def parse_sarif(name: str):
            raw = read_text(name)
            if not raw.strip():
              return None
            try:
              data = json.loads(raw)
            except json.JSONDecodeError:
              return None
            runs = data.get("runs", [])
            if not runs:
              return {"total": 0, "levels": {}}
            results = runs[0].get("results", [])
            rules = runs[0].get("tool", {}).get("driver", {}).get("rules", [])
            default_level = {r.get("id"): r.get("defaultConfiguration", {}).get("level") for r in rules}
            levels = Counter()
            for item in results:
              lvl = item.get("level") or default_level.get(item.get("ruleId")) or "unknown"
              levels[lvl] += 1
            return {"total": len(results), "levels": dict(sorted(levels.items()))}

          def parse_trivy_severity(name: str):
            raw = read_text(name)
            if not raw.strip():
              return None
            try:
              data = json.loads(raw)
            except json.JSONDecodeError:
              return None
            runs = data.get("runs", [])
            if not runs:
              return None
            rules = runs[0].get("tool", {}).get("driver", {}).get("rules", [])
            results = runs[0].get("results", [])
            sev_by_rule = {}
            for rule in rules:
              rid = rule.get("id")
              tags = rule.get("properties", {}).get("tags", [])
              sev = None
              for t in tags:
                tt = str(t).upper()
                if tt in {"CRITICAL", "HIGH", "MEDIUM", "LOW", "UNKNOWN"}:
                  sev = tt
                  break
              sev_by_rule[rid] = sev or "UNKNOWN"
            counts = Counter()
            for item in results:
              counts[sev_by_rule.get(item.get("ruleId"), "UNKNOWN")] += 1
            return dict(sorted(counts.items()))

          def parse_flake8():
            raw = read_text("flake8.txt")
            if not raw:
              return None
            lines = [x for x in raw.splitlines() if x.strip()]
            counts = Counter()
            for ln in lines:
              m = re.search(r":\s*([A-Z]\d{3})\b", ln)
              if m:
                counts[m.group(1)] += 1
            top = ", ".join(f"{k}:{v}" for k, v in counts.most_common(8))
            return {"total": len(lines), "top": top}

          def parse_pylint():
            raw = read_text("pylint.txt")
            if not raw:
              return None
            m = re.search(r"rated at\s+([0-9.]+)/10", raw)
            score = m.group(1) if m else "N/A"
            return {"score": score}

          def parse_safety():
            raw_text = read_text("safety.txt")
            raw_json = read_text("safety.json")
            if raw_json:
              try:
                data = json.loads(raw_json)
                if isinstance(data, dict):
                  vulns = data.get("vulnerabilities")
                  if isinstance(vulns, list):
                    return {"total": str(len(vulns))}
              except json.JSONDecodeError:
                pass
            if not raw_text:
              return None
            # Strip ANSI sequences from Safety text output for robust parsing.
            cleaned = re.sub(r"\x1b\[[0-9;]*m", "", raw_text)
            m = re.search(r"(\d+)\s+vulnerabilities found", cleaned, flags=re.IGNORECASE)
            total = m.group(1) if m else "N/A"
            return {"total": total}

          def parse_tests():
            raw = read_text("unit-tests.txt")
            if not raw:
              return None
            m = re.search(r"Found\s+(\d+)\s+test\(s\)", raw)
            total = m.group(1) if m else "N/A"
            return {"total": total}

          def parse_trufflehog():
            path = report_dir / "trufflehog.json"
            if not path.exists():
              return None
            findings = 0
            for line in path.read_text(encoding="utf-8", errors="replace").splitlines():
              line = line.strip()
              if not line:
                continue
              try:
                obj = json.loads(line)
                if isinstance(obj, dict):
                  findings += 1
              except json.JSONDecodeError:
                pass
            return {"total": findings}

          def parse_dependency_check():
            path = report_dir / "dependency-check" / "dependency-check-report.json"
            if not path.exists():
              return None
            try:
              data = json.loads(path.read_text(encoding="utf-8", errors="replace"))
            except json.JSONDecodeError:
              return None
            if data.get("status") == "missing":
              return {"missing": True, "message": data.get("message", "report missing")}
            deps = data.get("dependencies", [])
            cves = 0
            for dep in deps:
              cves += len(dep.get("vulnerabilities") or [])
            return {"dependencies": len(deps), "cves": cves}

          def parse_zap():
            path = report_dir / "zap-report.json"
            if not path.exists():
              return None
            raw = path.read_text(encoding="utf-8", errors="replace").strip()
            if not raw:
              return None
            try:
              data = json.loads(raw)
            except json.JSONDecodeError:
              return {"status": "available"}
            if isinstance(data, dict) and data.get("status") == "missing":
              return {"status": "missing", "message": data.get("message", "report missing")}
            sites = data.get("site", []) if isinstance(data, dict) else []
            counts = Counter()
            total = 0
            risk_map = {"0": "info", "1": "low", "2": "medium", "3": "high"}
            for site in sites:
              for alert in site.get("alerts", []):
                risk = risk_map.get(str(alert.get("riskcode", "")), "unknown")
                instances = alert.get("instances") or []
                n = len(instances) if instances else 1
                counts[risk] += n
                total += n
            return {"status": "available", "alerts": total, "levels": dict(sorted(counts.items()))}

          semgrep = parse_sarif("semgrep.sarif")
          trivy_deps = parse_sarif("trivy-deps.sarif")
          trivy_image = parse_sarif("trivy-image.sarif")
          gitleaks = parse_sarif("gitleaks.sarif")
          flake8 = parse_flake8()
          pylint = parse_pylint()
          safety = parse_safety()
          tests = parse_tests()
          trufflehog = parse_trufflehog()
          depcheck = parse_dependency_check()
          zap = parse_zap()
          trivy_deps_sev = parse_trivy_severity("trivy-deps.sarif")
          trivy_image_sev = parse_trivy_severity("trivy-image.sarif")

          def fmt_levels(obj):
            if not obj or not obj.get("levels"):
              return "-"
            return ", ".join(f"{k}:{v}" for k, v in obj["levels"].items())

          lines = [
            "# DevSecOps Report Summary",
            "",
            "| Tool | Key Results |",
            "|---|---|",
            f"| Unit tests | discovered={tests['total'] if tests else 'N/A'} |",
            f"| Flake8 | issues={flake8['total'] if flake8 else 'N/A'}; top={flake8['top'] if flake8 else '-'} |",
            f"| Pylint | score={pylint['score'] if pylint else 'N/A'}/10 |",
            f"| Safety | vulnerabilities={safety['total'] if safety else 'N/A'} |",
            f"| OWASP Dependency-Check | " + (
              f"dependencies={depcheck['dependencies']}; CVEs={depcheck['cves']}" if depcheck and not depcheck.get('missing')
              else (depcheck.get('message', 'N/A') if depcheck else 'N/A')
            ) + " |",
            f"| OWASP ZAP (DAST) | " + (
              f"report=available; alerts={zap.get('alerts', 'N/A')}; levels={fmt_levels(zap)}" if zap and zap.get("status") == "available"
              else (zap.get("message", "report missing") if zap else "N/A")
            ) + " |",
            f"| Semgrep (SARIF) | findings={semgrep['total'] if semgrep else 'N/A'}; levels={fmt_levels(semgrep)} |",
            f"| Trivy deps (SARIF) | findings={trivy_deps['total'] if trivy_deps else 'N/A'}; levels={fmt_levels(trivy_deps)}; severities={', '.join([f'{k}:{v}' for k,v in (trivy_deps_sev or {}).items()]) if trivy_deps_sev else 'N/A'} |",
            f"| Trivy image (SARIF) | findings={trivy_image['total'] if trivy_image else 'N/A'}; levels={fmt_levels(trivy_image)}; severities={', '.join([f'{k}:{v}' for k,v in (trivy_image_sev or {}).items()]) if trivy_image_sev else 'N/A'} |",
            f"| Gitleaks (SARIF) | findings={gitleaks['total'] if gitleaks else 'N/A'}; levels={fmt_levels(gitleaks)} |",
            f"| TruffleHog (JSON) | findings={trufflehog['total'] if trufflehog else 'N/A'} |",
            "",
            "## Files",
            "",
          ]

          for p in sorted(report_dir.glob("**/*")):
            if p.is_file():
              rel = p.relative_to(report_dir)
              lines.append(f"- `{rel.as_posix()}`")

          summary_path.write_text("\n".join(lines) + "\n", encoding="utf-8")
          print(summary_path.read_text(encoding="utf-8"))
          PY

      - name: Publish summary to workflow run
        if: always()
        shell: bash
        run: |
          cat "${{ steps.project.outputs.dir }}/reports/summary.md" >> "$GITHUB_STEP_SUMMARY"

      - name: Upload reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: devsecops-reports
          path: ${{ steps.project.outputs.dir }}/reports
